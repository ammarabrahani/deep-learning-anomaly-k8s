
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Performance Comparison\n",
    "This notebook compares Deep Q-Learning (DQL) performance against Autoencoder, Isolation Forest, Local Outlier Factor, and MLP Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison table\n",
    "data = {\n",
    "    'Model': ['Deep Q-Learning (DQL)', 'Autoencoder', 'Isolation Forest', 'Local Outlier Factor', 'MLP Classifier'],\n",
    "    'Type': ['Reinforcement Learning', 'Unsupervised NN', 'Unsupervised Classical', 'Unsupervised Classical', 'Supervised NN'],\n",
    "    'Macro Avg F1-Score': [0.61, 0.9107, 0.8947, 0.4302, 0.8951],\n",
    "    'Accuracy': [0.8, 0.9778, 0.98, 0.85, 0.96]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot DQL performance over episodes\n",
    "episodes = list(range(1, 21))\n",
    "f1_scores = [0.3, 0.38, 0.42, 0.47, 0.5, 0.53, 0.55, 0.57, 0.58, 0.59,\n",
    "             0.595, 0.6, 0.605, 0.61, 0.612, 0.615, 0.617, 0.619, 0.62, 0.621]\n",
    "\n",
    "autoencoder_f1 = 0.9107\n",
    "isolation_forest_f1 = 0.8947\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(episodes, f1_scores, marker='o', label='DQL (Episode-wise)', linewidth=2)\n",
    "plt.axhline(y=autoencoder_f1, color='green', linestyle='--', label='Autoencoder F1 = 0.9107')\n",
    "plt.axhline(y=isolation_forest_f1, color='red', linestyle='--', label='Isolation Forest F1 = 0.8947')\n",
    "\n",
    "plt.xlabel('Episodes')\n",
    "plt.ylabel('Macro F1-Score')\n",
    "plt.title('Deep Q-Learning (DQL) Macro F1-Score Over Episodes vs Other Models')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP Classifier Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = '''\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "      Normal     0.9562    1.0000    0.9776       262\n",
    "     Anomaly     1.0000    0.6842    0.8125        38\n",
    "\n",
    "    accuracy                         0.9600       300\n",
    "   macro avg     0.9781    0.8421    0.8951       300\n",
    "weighted avg     0.9618    0.9600    0.9567       300\n",
    "'''\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
