{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8854001",
   "metadata": {},
   "source": [
    "\n",
    "# MLP Classifier for Imbalanced Binary Classification\n",
    "\n",
    "**Author**: Ammar Yousuf Abrahani \n",
    "**Course/Project**: A Novel Deep Q Learning Aomaly Detection  \n",
    "\n",
    "---\n",
    "\n",
    "### Description:\n",
    "This notebook demonstrates how to build and evaluate a simple Multi-Layer Perceptron (MLP) using TensorFlow/Keras for binary classification on an imbalanced dataset. The dataset is synthetically generated using `make_classification` from scikit-learn. One class is underrepresented to simulate real-world anomaly or fraud detection scenarios.\n",
    "\n",
    "The model is evaluated using accuracy, precision, recall, and macro F1-score to assess its performance in handling class imbalance.\n",
    "\n",
    "---\n",
    "\n",
    "### References and Source Links:\n",
    "- [TensorFlow Keras Sequential Model](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential)  \n",
    "- [Keras Dense Layer](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense)  \n",
    "- [scikit-learn make_classification](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html)  \n",
    "- [scikit-learn train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)  \n",
    "- [scikit-learn classification_report](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html)  \n",
    "- [scikit-learn F1-score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html)  \n",
    "\n",
    "---\n",
    "\n",
    "> **Disclaimer**: This notebook is intended for academic and educational use. Please cite the sources if reused or adapted.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d133f25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db71ed0",
   "metadata": {},
   "source": [
    "## Step 1: Generate Synthetic Imbalanced Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5223492",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Generate synthetic classification dataset\n",
    "X, y = make_classification(\n",
    "    n_samples=1000,\n",
    "    n_features=4,\n",
    "    n_informative=3,\n",
    "    n_redundant=1,\n",
    "    n_clusters_per_class=1,\n",
    "    weights=[0.9, 0.1],  # Imbalanced dataset\n",
    "    flip_y=0.01,\n",
    "    random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258ca015",
   "metadata": {},
   "source": [
    "## Step 2: Split Data into Training and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99d3527f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58839b7",
   "metadata": {},
   "source": [
    "## Step 3: Define and Train MLP Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bac17d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\NCI-Research-Project\\code\\venv_tf\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9045 - loss: 0.5618 - val_accuracy: 0.8929 - val_loss: 0.3799\n",
      "Epoch 2/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9293 - loss: 0.3067 - val_accuracy: 0.8929 - val_loss: 0.2790\n",
      "Epoch 3/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9115 - loss: 0.2390 - val_accuracy: 0.9071 - val_loss: 0.2356\n",
      "Epoch 4/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9344 - loss: 0.2057 - val_accuracy: 0.9143 - val_loss: 0.2042\n",
      "Epoch 5/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9450 - loss: 0.1578 - val_accuracy: 0.9214 - val_loss: 0.1821\n",
      "Epoch 6/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9516 - loss: 0.1489 - val_accuracy: 0.9286 - val_loss: 0.1683\n",
      "Epoch 7/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9374 - loss: 0.1420 - val_accuracy: 0.9214 - val_loss: 0.1644\n",
      "Epoch 8/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9359 - loss: 0.1431 - val_accuracy: 0.9214 - val_loss: 0.1630\n",
      "Epoch 9/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9489 - loss: 0.1183 - val_accuracy: 0.9286 - val_loss: 0.1571\n",
      "Epoch 10/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9685 - loss: 0.1121 - val_accuracy: 0.9286 - val_loss: 0.1606\n",
      "Epoch 11/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9517 - loss: 0.0905 - val_accuracy: 0.9286 - val_loss: 0.1505\n",
      "Epoch 12/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9667 - loss: 0.0839 - val_accuracy: 0.9286 - val_loss: 0.1469\n",
      "Epoch 13/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9622 - loss: 0.0855 - val_accuracy: 0.9286 - val_loss: 0.1422\n",
      "Epoch 14/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9726 - loss: 0.0961 - val_accuracy: 0.9357 - val_loss: 0.1466\n",
      "Epoch 15/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9616 - loss: 0.0863 - val_accuracy: 0.9286 - val_loss: 0.1419\n",
      "Epoch 16/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9531 - loss: 0.1073 - val_accuracy: 0.9357 - val_loss: 0.1390\n",
      "Epoch 17/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9532 - loss: 0.1063 - val_accuracy: 0.9357 - val_loss: 0.1346\n",
      "Epoch 18/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9687 - loss: 0.0926 - val_accuracy: 0.9429 - val_loss: 0.1339\n",
      "Epoch 19/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9789 - loss: 0.0708 - val_accuracy: 0.9429 - val_loss: 0.1293\n",
      "Epoch 20/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9438 - loss: 0.1083 - val_accuracy: 0.9429 - val_loss: 0.1249\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2310c547020>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Build and compile MLP model\n",
    "model = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.compile(optimizer=Adam(0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train model\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=16, validation_split=0.2, verbose=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640cc500",
   "metadata": {},
   "source": [
    "## Step 4: Evaluate the Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0174d0fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "ğŸ“Š MLP Classifier Performance:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal     0.9560    0.9962    0.9757       262\n",
      "     Anomaly     0.9630    0.6842    0.8000        38\n",
      "\n",
      "    accuracy                         0.9567       300\n",
      "   macro avg     0.9595    0.8402    0.8879       300\n",
      "weighted avg     0.9569    0.9567    0.9534       300\n",
      "\n",
      "Macro Average F1-Score: 0.8879\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Evaluate model\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(int)\n",
    "report = classification_report(y_test, y_pred, target_names=['Normal', 'Anomaly'], digits=4)\n",
    "f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "print(\"ğŸ“Š MLP Classifier Performance:\\n\")\n",
    "print(report)\n",
    "print(f\"Macro Average F1-Score: {f1_macro:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
